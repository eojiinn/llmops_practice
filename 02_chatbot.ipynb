{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "aws_region = os.getenv(\"AWS_DEFAULT_REGION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Wawa! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to talk about or any questions you have?\" additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 38, 'total_tokens': 53}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 38, 'total_tokens': 53}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} id='run-9612eb58-3ada-4240-ba80-2b48fb7bd7c4-0' usage_metadata={'input_tokens': 15, 'output_tokens': 38, 'total_tokens': 53}\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock  # Bedrock 모델 사용\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Bedrock 모델 설정\n",
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "result = model.invoke([HumanMessage(content=\"Hi, I'm Wawa.\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='죄송합니다만, 저는 당신이 누구신지 정확히 알 수 없습니다. 저는 인공지능 챗봇으로, 개인정보를 저장하거나 기억하지 않습니다. 대화 상대방에 대한 구체적인 정보 없이 일반적인 대화만 가능합니다. 무엇을 도와드릴까요?', additional_kwargs={'usage': {'prompt_tokens': 16, 'completion_tokens': 129, 'total_tokens': 145}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 16, 'completion_tokens': 129, 'total_tokens': 145}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-98c7ea26-d18b-4a8e-899a-4565ec98eecb-0', usage_metadata={'input_tokens': 16, 'output_tokens': 129, 'total_tokens': 145})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"내가 누구라고?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대화 기억 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='당신의 이름은 밥이라고 하셨습니다.', additional_kwargs={'usage': {'prompt_tokens': 69, 'completion_tokens': 25, 'total_tokens': 94}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 69, 'completion_tokens': 25, 'total_tokens': 94}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-5d51e0f8-db3a-421b-b7c8-31f2c9f7f978-0', usage_metadata={'input_tokens': 69, 'output_tokens': 25, 'total_tokens': 94})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 대화 기록을 포함한 모델 호출\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕하세요! 저는 밥입니다.\"),\n",
    "        AIMessage(content=\"안녕하세요 밥! 무엇을 도와드릴까요?\"),\n",
    "        HumanMessage(content=\"제 이름이 뭐죠?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메시지 지속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# 새로운 그래프 정의\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 모델 호출 함수 정의\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 노드 및 메모리 설정\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)  # 아무튼 시작하자마자 call_model을 부르겠다\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스레드별 대화 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 밥 님! 만나서 반갑습니다. 제 이름은 Claude입니다. 오늘 어떤 도움이 필요하신가요? 궁금한 점이나 이야기 나누고 싶은 주제가 있으시면 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "query = \"안녕하세요! 저는 밥입니다.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요! 저는 밥입니다.', additional_kwargs={}, response_metadata={}, id='e41143b8-0efd-460c-ba92-110b1e24cb72'),\n",
       "  AIMessage(content='안녕하세요, 밥 님! 반갑습니다. 오늘 어떤 도움이 필요하신가요? 궁금한 점이나 이야기하고 싶은 주제가 있다면 말씀해 주세요. 제가 최선을 다해 도와드리겠습니다.', additional_kwargs={'usage': {'prompt_tokens': 25, 'completion_tokens': 103, 'total_tokens': 128}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 25, 'completion_tokens': 103, 'total_tokens': 128}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-5424761b-d46e-4284-9809-1bc66ea6309e-0', usage_metadata={'input_tokens': 25, 'output_tokens': 103, 'total_tokens': 128}),\n",
       "  HumanMessage(content='제 이름이 무엇이었나요?', additional_kwargs={}, response_metadata={}, id='58965b54-4e13-42f5-a574-efcc6baf1358'),\n",
       "  AIMessage(content='당신의 이름은 밥이라고 말씀하셨습니다.', additional_kwargs={'usage': {'prompt_tokens': 146, 'completion_tokens': 28, 'total_tokens': 174}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 146, 'completion_tokens': 28, 'total_tokens': 174}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-18dc18fd-5943-401e-b876-aa158e3c5b5f-0', usage_metadata={'input_tokens': 146, 'output_tokens': 28, 'total_tokens': 174}),\n",
       "  HumanMessage(content='제 이름이 무엇이었나요?', additional_kwargs={}, response_metadata={}, id='424a5aa2-cb84-4e95-9d33-317095c8e9a2'),\n",
       "  AIMessage(content='죄송합니다만, 제가 앞서 말씀드린 대로 당신의 이름은 밥이라고 하셨습니다. 혹시 다른 이름을 말씀하셨다면 제가 잘못 이해했을 수 있습니다. 정확한 이름을 다시 알려주시겠습니까?', additional_kwargs={'usage': {'prompt_tokens': 192, 'completion_tokens': 112, 'total_tokens': 304}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, response_metadata={'usage': {'prompt_tokens': 192, 'completion_tokens': 112, 'total_tokens': 304}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-65b98b27-1731-4aae-98a6-279def03a3ad-0', usage_metadata={'input_tokens': 192, 'output_tokens': 112, 'total_tokens': 304})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"제 이름이 무엇이었나요?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "죄송합니다만, 제가 앞서 말씀드린 대로 당신의 이름은 밥이라고 하셨습니다. 혹시 다른 이름을 말씀하셨다면 제가 잘못 이해했을 수 있습니다. 정확한 이름을 다시 알려주시겠습니까?\n"
     ]
    }
   ],
   "source": [
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "죄송합니다만, 저는 귀하의 이름을 알지 못합니다. 우리는 이전에 대화를 나눈 적이 없고, 저는 개인 정보를 저장하지 않습니다. 혹시 제가 도와드릴 다른 것이 있나요?\n"
     ]
    }
   ],
   "source": [
    "# config를 바꾸면 다시 기억을 못함\n",
    "config = {'configurable': {'thread_id': 'abc234'}}\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비동기 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n"
     ]
    }
   ],
   "source": [
    "# 비동기 모델 호출 함수 정의\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 비동기 호출\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 해적처럼 말하는 프롬프트 템플릿 설정\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"인터넷 말투로 대답해. '음슴체'로 대답해. 모든 질문에 최선을 다해 답변해.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프롬프트와 모델 결합 (그래프 재정의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿을 모델과 결합\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "def call_model(state: MessagesState):\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke(state)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ㅇㅈ... 배고픈 거 진짜 힘들죠 ㅠㅠ 집에 가서 맛있는 거 먹음 좋을 듯요... 근데 아직 일이나 공부 끝나지 않았음 조금만 더 힘내보는 것도 좋을 거 같음... 화이팅임!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"배고프고 집에 가고싶다.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대화 기록 관리 최적화\n",
    "대화 기록이 너무 길어지면 어떻게 처리할까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뒷부분만 가져오도록 함\n",
    "\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# 메시지 트리머 설정\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    ")\n",
    "\n",
    "# 트리머로 메시지 관리\n",
    "messages = [\n",
    "    HumanMessage(content=\"안녕하세요! 저는 밥입니다.\"),\n",
    "    AIMessage(content=\"안녕하세요!\"),\n",
    "    HumanMessage(content=\"2 더하기 2는?\"),\n",
    "    AIMessage(content=\"4입니다.\"),\n",
    "]\n",
    "\n",
    "# 메시지 트리밍 후 처리\n",
    "trimmed_messages = trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='안녕하세요! 저는 밥입니다.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='2 더하기 2는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4입니다.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿을 모델과 결합\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "def call_model(state: MessagesState):\n",
    "    chain = prompt | model\n",
    "    trimmed_messages = trimmer.invoke(state['message'])\n",
    "    response = chain.invoke(trimmed_messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "아 ㅇㅇ 진짜 배고픈 거 실화임? 집 가서 맛있는 거 먹고 싶은 거 이해함 ㅠㅠ 근데 지금 집에 갈 수 있음? 아니면 근처에 편의점이나 간단히 먹을 만한 거 있음? 아님 배달 시키는 것도 괜찮음! 힘내셈 곧 집에 갈 수 있을 거임!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"배고프고 집에 가고싶다.\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스트리밍 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|안녕|하세용| |ㅎㅎ| 또| 다|른 농담| 들|려|드|릴게용|\n",
      "\n",
      "왜 수|학|책|은| 우|울|할|까용?|\n",
      "\n",
      "문|제가| 너|무 많|아서임| |ㅋㅋ|ㅋ|ㅋ|\n",
      "\n",
      "|좀| |뻔한 농|담이지만| 그래도| 웃|겨드|리|고| 싶었|음|다| |ㅎㅎ| |\n",
      "재|미없|어|도| 이|해해주심| 감사함| |ㅠ|ㅠ|||"
     ]
    }
   ],
   "source": [
    "# 메시지를 실시간으로 출력\n",
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "input_messages = [HumanMessage(\"안녕하세요, 농담 하나 해주세요!\")]\n",
    "\n",
    "# 실시간 응답 스트림\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):\n",
    "        print(chunk.content, end=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
