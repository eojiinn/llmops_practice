{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith 설정\n",
    "LangSmith를 통해 애플리케이션 내부 단계를 추적하고 분석 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langchain_tracing = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "aws_region = os.getenv(\"AWS_DEFAULT_REGION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언어 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='안녕하세요!' additional_kwargs={'usage': {'prompt_tokens': 17, 'completion_tokens': 11, 'total_tokens': 28}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} response_metadata={'usage': {'prompt_tokens': 17, 'completion_tokens': 11, 'total_tokens': 28}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-5-sonnet-20240620-v1:0'} id='run-26e76738-22ed-4916-b980-606eaf0054ce-0' usage_metadata={'input_tokens': 17, 'output_tokens': 11, 'total_tokens': 28}\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock  # Bedrock 모델 사용\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Bedrock 모델 설정\n",
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "# 영어에서 이탈리아어로 번역하는 예시\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Korean\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Korean', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.invoke('LLMOps에 대해서 소개해줘')\n",
    "result = model.invoke('너는 영어로 ')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutputParser 사용\n",
    "OutputParser를 사용하여 결과의 텍스트만 추출할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMOps(Large Language Model Operations)는 대규모 언어 모델(LLM)의 개발, 배포, 유지보수 및 모니터링을 위한 일련의 실무와 프로세스를 말합니다. 이는 MLOps(Machine Learning Operations)의 개념을 LLM에 특화시킨 것으로 볼 수 있습니다.\n",
      "\n",
      "LLMOps의 주요 특징과 구성요소는 다음과 같습니다:\n",
      "\n",
      "1. 모델 개발 및 훈련:\n",
      "   - 데이터 수집 및 전처리\n",
      "   - 모델 아키텍처 설계\n",
      "   - 하이퍼파라미터 튜닝\n",
      "   - 분산 학습 및 최적화\n",
      "\n",
      "2. 배포 및 서빙:\n",
      "   - 모델 압축 및 최적화\n",
      "   - 컨테이너화 및 오케스트레이션\n",
      "   - API 개발 및 관리\n",
      "   - 스케일링 및 로드 밸런싱\n",
      "\n",
      "3. 모니터링 및 유지보수:\n",
      "   - 성능 모니터링\n",
      "   - 데이터 드리프트 감지\n",
      "   - 모델 업데이트 및 재훈련\n",
      "   - 버전 관리\n",
      "\n",
      "4. 보안 및 규정 준수:\n",
      "   - 데이터 프라이버시 보호\n",
      "   - 편향성 감지 및 완화\n",
      "   - 윤리적 AI 사용 보장\n",
      "   - 규제 준수\n",
      "\n",
      "5. 인프라 관리:\n",
      "   - 클라우드 리소스 최적화\n",
      "   - 비용 관리\n",
      "   - 고가용성 및 재해 복구\n",
      "\n",
      "6. 협업 및 워크플로우:\n",
      "   - 버전 제어 시스템 통합\n",
      "   - CI/CD 파이프라인 구축\n",
      "   - 팀 협업 도구 활용\n",
      "\n",
      "7. 실험 및 평가:\n",
      "   - A/B 테스팅\n",
      "   - 성능 벤치마킹\n",
      "   - 사용자 피드백 수집 및 분석\n",
      "\n",
      "LLMOps는 LLM의 복잡성과 규모로 인해 전통적인 MLOps보다 더 많은 도전과제를 안고 있습니다. 예를 들어, 모델 크기로 인한 컴퓨팅 자원 관리, 지속적인 학습 및 개선, 윤리적 고려사항 등이 있습니다.\n",
      "\n",
      "효과적인 LLMOps 구현은 LLM 프로젝트의 성공적인 운영과 지속 가능한 발전을 위해 필수적입니다. 이를 통해 조직은 LLM의 잠재력을 최대한 활용하면서도 안정성, 확장성, 그리고 책임 있는 AI 사용을 보장할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 파서 설정\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 모델 결과를 파서로 처리\n",
    "parsed_result = parser.invoke(result)\n",
    "print(parsed_result)  # 출력: '안녕!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 체인으로 모델과 파서 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model, parser를 한번에 invoke\n",
    "# vars = [model, parser]\n",
    "# for var in vars:\n",
    "#     var.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_result = chain.invoke(messages)\n",
    "parsed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='Translate the following into korean:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 시스템 메시지 템플릿 생성\n",
    "system_template = \"Translate the following into {language}:\"\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n",
    "\n",
    "# 템플릿 호출\n",
    "prompt_result = prompt_template.invoke({\"language\": \"korean\", \"text\": \"hi\"})\n",
    "print(prompt_result.to_messages())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 (annyeonghaseyo)\n",
      "\n",
      "This is a common Korean greeting that can be used in both formal and informal situations. It's equivalent to \"hello\" in English.\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트, 모델, 파서를 결합한 체인 생성\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "# 체인 호출\n",
    "result = chain.invoke({\"language\": \"korean\", \"text\": \"hi\"})\n",
    "print(result)  # 출력: 'ciao'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서버 파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
